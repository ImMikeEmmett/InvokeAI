{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy86JeXPHQmW"
      },
      "source": [
        "# InvokeAI in Google Colab\n",
        "Make sure to enable GPU, Edit > Notebook Settings > Hardware accelerator > GPU <br>\n",
        "This takes about 10-12 Mins to start fully.<br>\n",
        "To start, Click \"Runtime\" > \"Run All\".<br>\n",
        "Adapted from:\n",
        "https://github.com/jenkinsmichpa/invokeai-colab/blob/main/invokeai-colab.ipynb <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cEAEBY2sFdGR"
      },
      "outputs": [],
      "source": [
        "#@title 1. Configuration { display-mode: \"form\" }\n",
        "#@markdown <u>Instance Type</u><br>\n",
        "#@markdown Persistent = Stores images in your Google drive, in a folder called \"/invokeaiOutput\".<br>\n",
        "#@markdown Temp = Images are stored in the runtime and are removed when the runtime ends or crashes. Make sure to download your images! <br>\n",
        "Type = \"Persistent\" #@param ['Persistent','Temp'] {type:\"string\"}\n",
        "#@markdown <u>Xformers</u><br>\n",
        "#@markdown Xformers makes this \"memory efficient\" so larger images (above 1024x1024) can be made, However it can be less stable and may generate blank outputs. It is recomended that you set it to \"Enabled\" unless you experiance issues with your models.\n",
        "xformers = \"Enabled\" #@param ['Enabled' ,'Disabled'] {type:\"string\"}\n",
        "#@markdown <u>NSFW Checker</u><br>\n",
        "#@markdown This checks outputs for \"Not Safe For Work\" content and obscures the image.\n",
        "nsfw_checker = \"Enabled\" #@param ['Enabled' ,'Disabled'] {type:\"string\"}\n",
        "#@markdown <u>Custom checkpoint / safetensor Model</u>\n",
        "custom_model_url = \"None\" #@param [\"None\",\"https://huggingface.co/ffggggfg/Crosskemono/resolve/main/crosskemonoFurryModel_crosskemono25.safetensors\"] {allow-input: true}\n",
        "custom_vae_url = \"None\" #@param [\"None\",\"https://huggingface.co/ffggggfg/Crosskemono/resolve/main/Crosskemono2.vae.pt\"] {allow-input: true}\n",
        "#@markdown Custom models are stored in /content/invokeai/CustomModels and must be manually added via the GUI after it starts. <br>\n",
        "#@markdown The Custom VAE will be stored in /content/invokeai/CustomVae <br>\n",
        "#@markdown <br>\n",
        "#@markdown <u>NGROK - Recomended, but not required.</u><br>\n",
        "#@markdown An NGROK token is needed for the more stable connection, however this project gives 2 options on how to connect, if you are happy with the less stable \"Localtunnel\" Leave this as \"none\".<br>\n",
        "#@markdown Sign up and get your free token at https://ngrok.com/\n",
        "ngrok_token = \"None\" #@param ['None'] {allow-input: true}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrEl_CcOHJYh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 2. Build and configure.\n",
        "#@markdown This takes about 10-12 mins to finish + any extra time to download custom models. { display-mode: \"form\" }\n",
        "%%capture\n",
        "file_path = '/content/invokeai'\n",
        "\n",
        "#Set up temporary storage if needed\n",
        "if Type == \"Temp\":\n",
        "    outpath = '/content/invokeai/output'\n",
        "    import os\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "\n",
        "# Mount and set up Google drive if needed.\n",
        "if Type == \"Persistent\":\n",
        "  outpath = '/content/drive/MyDrive/invokeaiOutput'\n",
        "  import os\n",
        "  from google.colab import drive\n",
        "  if not os.path.exists(file_path):\n",
        "    drive.mount('/content/drive')\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "\n",
        "\n",
        "#Install Python + Pip\n",
        "\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9 python3-pip python3.9-distutils python3.9-dev libpython3.9-dev python3.9-venv -y\n",
        "\n",
        "#Change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "\n",
        "#Update pip\n",
        "#%cd {file_path}\n",
        "#!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "#!python3 get-pip.py --force-reinstall/\n",
        "#!python -m pip install --upgrade pip\n",
        "#!pip install --upgrade setuptools\n",
        "\n",
        "#Handle colab dependencies\n",
        "!ln -s /usr/local/lib/python3.8/dist-packages/google /usr/local/lib/python3.9/dist-packages/google\n",
        "!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "#Create InvokeAI root\n",
        "import os\n",
        "os.environ['INVOKEAI_ROOT'] = file_path\n",
        "if not os.path.exists(file_path):\n",
        "  os.makedirs(invokeai_root)\n",
        "\n",
        "#Create and prepare virtual environment\n",
        "%cd {file_path}\n",
        "!python -m venv .venv --prompt InvokeAI\n",
        "!source .venv/bin/activate; python -m pip install --upgrade pip\n",
        "!source .venv/bin/activate; pip install InvokeAI[xformers] --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!mkdir {outpath}\n",
        "\n",
        "#Edit invokeai.init and download default models\n",
        "!cd {file_path}\n",
        "!source .venv/bin/activate; invokeai-configure --yes\n",
        "!sed -i 's/--max_loaded_models=2/--max_loaded_models=1/' invokeai.init\n",
        "if xformers == \"Disabled\":\n",
        "  !sed -i 's/--xformers/--no-xformers/' invokeai.init\n",
        "if nsfw_checker == \"Disabled\":\n",
        "  !sed -i 's/--nsfw_checker/--no-nsfw_checker/' invokeai.init\n",
        "\n",
        "\n",
        "#Download custom models\n",
        "if custom_model_url != \"None\":\n",
        "  !mkdir {file_path}/CustomModels\n",
        "  %cd {file_path}/CustomModels\n",
        "  !wget -nc {file_path}/CustomModels {custom_model_url}\n",
        "\n",
        "#Download custom VAE\n",
        "if custom_vae_url != \"None\":\n",
        "  !mkdir {file_path}/CustomVae\n",
        "  %cd {file_path}/CustomVae\n",
        "  !wget -nc {file_path}/CustomVae {custom_vae_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiWohNwq6UHN"
      },
      "outputs": [],
      "source": [
        "#@title 3. Connect via NGROK. { display-mode: \"form\" }\n",
        "#@markdown This link will start working when the next step tells you to connect to localhost.<br>\n",
        "#@markdown If this fails, See the next step for an alternate connection method.<br>\n",
        "#@markdown You can ignore this step if you have not suplied a NGROK token in the configuration.\n",
        "\n",
        "if ngrok_token != \"None\":\n",
        "  %cd {file_path}\n",
        "  !pip install pyngrok --quiet\n",
        "  from pyngrok import ngrok\n",
        "  ngrok.kill()\n",
        "  ngrok.set_auth_token(ngrok_token)\n",
        "  public_url = ngrok.connect(9090).public_url\n",
        "  print(f'InvokeAI Public URL: {public_url}')\n",
        "\n",
        "if ngrok_token == \"None\":\n",
        "  print(\"You have chosen not to use NGROK.\")\n",
        "  print(\"Please follow the connection process in step 4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnO01U-W6Yjp"
      },
      "outputs": [],
      "source": [
        "#@title 4. Conect via \"Localtunnel\" + Start InvokeAI { display-mode: \"form\" }\n",
        "#@markdown A \"localtunnel\" Interface connection is generated here, To use this, please do the following: <br>\n",
        "#@markdown 1) Copy the IP address stated in line 3 of this cells output. <br>\n",
        "#@markdown 2) Click the random \"https://XXX-YYY-ZZZ.loca.lt\" link in line 9. <br>\n",
        "#@markdown 3) Paste the IP into the provided box and submit. <br> <br>\n",
        "#@markdown Your downloaded model is stored at: /content/invokeai/CustomModels<br>\n",
        "#@markdown Your downloaded VAE is stored at: /content/invokeai/CustomVae <br>\n",
        "#@markdown <br>Diffuser models, can be added via the interface, <br>\n",
        "#@markdown Model manager > Add New > Add Diffusers > Give it any name/Discription > Put your \"Hugging face Repo ID\" into the \"Repo ID\" box > Add Model<br>\n",
        "#@markdown It will auto download and configure when it is first loaded<br><br>\n",
        "#@markdown <u>An Example Diffuser Model:</u><br>\n",
        "#@markdown kebab111/crosskemono - A Furry/Anime model<br>\n",
        "%cd {file_path}\n",
        "!echo IP address:\n",
        "!curl ipv4.icanhazip.com\n",
        "!npm install -g localtunnel\n",
        "!npx localtunnel --port 9090 & !source .venv/bin/activate; invokeai --web --host 0.0.0.0 --outdir={outpath}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Temp Mode - Zip Output for Download.\n",
        "#@markdown Google Colab does not give a nice way to download multiple files at once.<br>\n",
        "#@markdown When running in Temp Mode, This will compress all images into a single \"output.zip\" to make downloading everything simple!<br>\n",
        "#@markdown This file can be downloaded using the Colab file browser: /invokeai/output/Output.zip <br>\n",
        "#@markdown For this step to run you must manually stop step 4.\n",
        "\n",
        "if Type == \"Temp\":\n",
        "  !mkdir /content/zip\n",
        "  !rm {outpath}/Output.zip\n",
        "  !rm -r /content/zip/*\n",
        "  !cp -p {outpath}/*png /content/zip\n",
        "  !cd /content/zip/\n",
        "  !zip {outpath}/Output.zip /content/zip/*.png"
      ],
      "metadata": {
        "id": "V6GVH_Km8JgK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}