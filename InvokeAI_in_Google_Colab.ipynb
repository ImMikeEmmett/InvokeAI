{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy86JeXPHQmW"
      },
      "source": [
        "# InvokeAI in Google Colab\n",
        "\n",
        "This is a tool to use Google colab to run the AI image generation tool: Invokeai (https://invoke-ai.github.io/InvokeAI/).\n",
        "This automatically builds itself and can import your models, It can connect to Google drive to save your images.\n",
        "It also has the option of running entirely from Google drive to vastly speed up the time it takes to start, However, over 20Gb of Google Drive space is required! However it changes subsequent startup times from 15-20 mins to 4-5 mins.\n",
        "\n",
        "Make sure to enable GPU, Edit > Notebook Settings > Hardware accelerator > GPU\n",
        "\n",
        "To start, Click \"Runtime\" > \"Run All\". Alternaivly you can click the \"play\" button on each step below one after the other, No need to wait for the previous steps to finish as they will join a queue.<br>\n",
        "\n",
        "###Note: Currently, the Gui is bugged for V3.0.0 | To fix this, you need to use a \"Servio\" or \"Localtunnel\" connection type (NGROK does NOT work for this workaround) After launching the page, enable \"Insecure content\" in \"Site setings\" - A back-end fix is being worked on. - https://github.com/invoke-ai/InvokeAI/issues/3693\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cEAEBY2sFdGR"
      },
      "outputs": [],
      "source": [
        "#@title 1. Configuration { display-mode: \"form\" }\n",
        "#@markdown #Instance Type\n",
        "#@markdown **Google_Drive** = Stores ALL files in your google drive, This will take over 20Gb of space (Per Version), but will start up much faster as it does not download invokeai at each run. To make it download a fresh version simply delete the folder \"/content/drive/MyDrive/invokeai/invokeaiVERSION/noUpdate, or indeed the whole \"invokeaiVERSION\" folder as outputs are stored elsewhere.<br>\n",
        "#@markdown **Persistent** = Stores only your images in Google drive, in a folder called \"/invokeai/invokeaiOutput\" with the invoke version number on the end.<br>\n",
        "#@markdown **Temporary** (NOT recomended) = Everything is stored in the runtime and is removed when the runtime ends or crashes, make sure to download your images! <br><br>\n",
        "#@markdown **Rough Startup times:** <br>\n",
        "#@markdown V2.3.5 = 10-12 mins <br>\n",
        "#@markdown V3 (Temporary or Persistant modes or Google_Drive First run.) = 15-20 mins (Full) | 10 mins (Custom model ONLY) <br>\n",
        "#@markdown V3 \"Google_Drive\" = Subsiquent runs, 4-5 mins, or 6-7 mins if it is updating.\n",
        "Version = \"Version 3\" #@param ['Version 3','2.3.5.post2'] {type:\"string\"}\n",
        "Type = \"Google_Drive\" #@param ['Google_Drive','Persistent','Temporary'] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #Connection Type.\n",
        "#@markdown Serveo: Mediumly stable, requires no setup. <br>\n",
        "#@markdown Localtunnel: Less stable, also requires no setup. It is an alternate if for some reson 'Serveo' is not working. It also requires an extra step at connection time.<br>\n",
        "#@markdown NGROK: Highly stable but needs a little setting up, An NGROK token is required, sign up for free and get one here: https://dashboard.ngrok.com/get-started/your-authtoken Once you have the token, please put it in below.<br>\n",
        "connection_type = \"Serveo\"  #@param [\"Serveo\",\"Localtunnel\",\"NGROK\"]\n",
        "ngrok_token = \"None\" #@param ['None'] {allow-input: true}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #Custom Models\n",
        "#@markdown Skip Default Models: <br>\n",
        "#@markdown When installing for the first time, you can skip the default models to save about 10 mins and 30GB. This setting has no effect on a re-run (it does not add or remove existing models). You MUST specify a custom model if you choose to skip the default models. <br>\n",
        "#@markdown Skipping default models only works with V3+ <br>\n",
        "skip_default_models = \"No\" #@param [\"Yes\",\"No\"]\n",
        "#@markdown Custom Diffuser Model\n",
        "custom_diffuser_hugging_face_id = \"None\" #@param [\"None\",\"kebab111/crosskemono\", \"dreamlike-art/dreamlike-photoreal-2.0\", \"stablediffusionapi/disney-pixal-cartoon\"] {allow-input: true}\n",
        "#@markdown Custom Safetensor or Checkpoint models <br>\n",
        "custom_model_url = \"None\" #@param [\"None\",\"https://huggingface.co/ffggggfg/Crosskemono/resolve/main/crosskemonoFurryModel_crosskemono25.safetensors\"] {allow-input: true}\n",
        "custom_vae_url = \"None\" #@param [\"None\",\"https://huggingface.co/ffggggfg/Crosskemono/resolve/main/Crosskemono2.vae.pt\"] {allow-input: true}\n",
        "\n",
        "#@markdown If you have selected a custom diffuser model it will be auto imported and it is selectable from the dropdown menu in app. <br>\n",
        "#@markdown Custom .safetensor or .checkpoint models are stored in /content/invokeai/CustomModels and must be manually added via the GUI after it starts. Your Custom VAE will be stored in /content/invokeai/CustomVae <br>\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #NSFW Checker\n",
        "#@markdown This checks outputs for \"Not Safe For Work\" content and obscures the image. This is not 100% reliable.\n",
        "nsfw_checker = \"Enabled\" #@param ['Enabled' ,'Disabled'] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #Xformers\n",
        "#@markdown Xformers makes this \"memory efficient\" so larger images (above 1024x1024) can be made, However it can be less stable and may generate blank outputs. It is recomended that you set it to \"Enabled\" unless you experiance issues with your models.\n",
        "xformers = \"Enabled\" #@param ['Enabled' ,'Disabled'] {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrEl_CcOHJYh"
      },
      "outputs": [],
      "source": [
        "#@title 2.a. Build and Configure. (V2.3.5.post2) { display-mode: \"form\" }\n",
        "#@markdown This takes about 10-12 mins to finish + some extra time to download custom Checkpoint / Safetensor models.<br>\n",
        "#@markdown Version 2.3.5.post2 Downloads Checkpoint models now, and they must be manually added via the GUI.<br>\n",
        "#@markdown It will download and auto-add Diffuser models during startup.\n",
        "\n",
        "from IPython.display import clear_output\n",
        "if Version == \"2.3.5.post2\":\n",
        "  import os\n",
        "\n",
        "  #Set up temporary storage if running in \"Temporary\" mode.\n",
        "  if Type == \"Temporary\":\n",
        "      file_path = '/content/invokeai'\n",
        "      outpath = '/content/invokeai/output'\n",
        "      noUpdate = '/content/invokeai/noUpdate'\n",
        "\n",
        "      if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "  # Mount and set up Google drive if running in \"Persistent\" mode.\n",
        "  if Type == \"Persistent\":\n",
        "    file_path = '/content/invokeai'\n",
        "    outpath = '/content/drive/MyDrive/invokeai/invokeaiOutput2.3.5.post2'\n",
        "    noUpdate = '/content/invokeai/noUpdate'\n",
        "\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists(file_path):\n",
        "      drive.mount('/content/drive')\n",
        "      if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "  # Mount and set up Google drive if running in \"Google_Drive\" mode.\n",
        "  if Type == \"Google_Drive\":\n",
        "    file_path = '/content/drive/MyDrive/invokeai/invokeai2.3.5.post2'\n",
        "    outpath = '/content/drive/MyDrive/invokeai/invokeaiOutput2.3.5.post2'\n",
        "    noUpdate = '/content/drive/MyDrive/invokeai/invokeai2.3.5.post2/noUpdate'\n",
        "\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists(file_path):\n",
        "      drive.mount('/content/drive')\n",
        "      if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "  #Install Python + Pip\n",
        "  !sudo apt-get update -y\n",
        "  !sudo apt-get install python3.9 python3-pip python3.9-distutils python3.9-dev libpython3.9-dev python3.9-venv -y\n",
        "  #!sudo apt-get install python3.10 python3-pip python3.10-distutils python3.10-dev libpython3.10-dev python3.10-venv -y\n",
        "\n",
        "  #Change alternatives\n",
        "  !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 3\n",
        "\n",
        "  #Update pip\n",
        "  %cd {file_path}\n",
        "  !curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "  !python3 get-pip.py --force-reinstall\n",
        "  !python -m pip install --upgrade pip\n",
        "  !pip install --upgrade setuptools\n",
        "  !pip install pillow==9.3.0\n",
        "\n",
        "  #Handle colab dependencies\n",
        "  #!ln -s /usr/local/lib/python3.8/dist-packages/google /usr/local/lib/python3.9/dist-packages/google\n",
        "  #!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "  #Handle colab dependencies\n",
        "  !ln -s /usr/local/lib/python3.8/dist-packages/google /usr/local/lib/python3.9/dist-packages/google\n",
        "  !python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "  #Create InvokeAI root\n",
        "  import os\n",
        "  os.environ['INVOKEAI_ROOT'] = file_path\n",
        "  if not os.path.exists(file_path):\n",
        "    os.makedirs(invokeai_root)\n",
        "\n",
        "  #On 2nd run, do an \"upgrade\" to get system variables to load quickly.\n",
        "  if os.path.exists(noUpdate):\n",
        "    !python -m venv .venv --prompt InvokeAI\n",
        "    !source .venv/bin/activate; pip install InvokeAI[xformers]==2.3.5.post2 --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117 --upgrade\n",
        "\n",
        "  #Create the virtual environment + Download default models\n",
        "  %cd {file_path}\n",
        "  !python -m venv .venv --prompt InvokeAI\n",
        "  if not os.path.exists(noUpdate):\n",
        "    !source .venv/bin/activate; python -m pip install --upgrade pip\n",
        "    !source .venv/bin/activate; pip install InvokeAI[xformers]==2.3.5.post2 --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "    !source .venv/bin/activate; python -m pip uninstall torchmetrics==1.0.0 -y\n",
        "    !source .venv/bin/activate; python -m pip install torchmetrics==0.7.0\n",
        "    !mkdir {outpath}\n",
        "    !cd {file_path}\n",
        "    !source .venv/bin/activate; invokeai-configure --yes\n",
        "    !mkdir {noUpdate}\n",
        "\n",
        "  #Edit invokeai.init\n",
        "  !sed -i 's/--max_loaded_models=2/--max_loaded_models=1/' invokeai.init\n",
        "  if xformers == \"Disabled\":\n",
        "    !sed -i 's/--xformers/--no-xformers/' invokeai.init\n",
        "  if xformers == \"Enabled\":\n",
        "    !sed -i 's/--no-xformers/--xformers/' invokeai.init\n",
        "  if nsfw_checker == \"Disabled\":\n",
        "    !sed -i 's/--nsfw_checker/--no-nsfw_checker/' invokeai.init\n",
        "  if nsfw_checker == \"Enabled\":\n",
        "    !sed -i 's/--no-nsfw_checker/--nsfw_checker/' invokeai.init\n",
        "\n",
        "  #Download custom checkpoint models\n",
        "  if custom_model_url != \"None\":\n",
        "    !mkdir {file_path}/CustomModels\n",
        "    %cd {file_path}/CustomModels\n",
        "    !wget -nc {file_path}/CustomModels {custom_model_url}\n",
        "\n",
        "  #Download custom VAE\n",
        "  if custom_vae_url != \"None\":\n",
        "    !mkdir {file_path}/CustomVae\n",
        "    %cd {file_path}/CustomVae\n",
        "    !wget -nc {file_path}/CustomVae {custom_vae_url}\n",
        "\n",
        "  #Clear Output\n",
        "  clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.b. Build and Configure. (v3.0.1rc2) { display-mode: \"form\" }\n",
        "#@markdown This takes about 15 mins to finish + some extra time to download custom models. <br>\n",
        "#@markdown Version 3 Downloads all models during the build phase.<br>\n",
        "#@markdown It will auto add all models to the app.\n",
        "\n",
        "from IPython.display import clear_output\n",
        "if Version == \"Version 3\":\n",
        "\n",
        "  #Set up temporary storage if running in \"Temporary\" mode.\n",
        "  if Type == \"Temporary\":\n",
        "      file_path = '/content/invokeai'\n",
        "      outpath = '/content/invokeai/output'\n",
        "      noUpdate = '/content/invokeai/noUpdate'\n",
        "      import os\n",
        "      if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "  # Mount and set up Google drive if running in \"Persistent\" mode.\n",
        "  if Type == \"Persistent\":\n",
        "    file_path = '/content/invokeai'\n",
        "    outpath = '/content/drive/MyDrive/invokeaiOutputV3'\n",
        "    noUpdate = '/content/invokeai/noUpdate'\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists(file_path):\n",
        "      drive.mount('/content/drive')\n",
        "      if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "  # Mount and set up Google drive if running in \"Google_Drive\" mode.\n",
        "  if Type == \"Google_Drive\":\n",
        "    file_path = '/content/drive/MyDrive/invokeai/invokeaiV3'\n",
        "    outpath = '/content/drive/MyDrive/invokeai/invokeaiOutputV3'\n",
        "    noUpdate = '/content/drive/MyDrive/invokeai/invokeaiV3/noUpdate'\n",
        "\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists(file_path):\n",
        "      drive.mount('/content/drive')\n",
        "      if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "  #Install Python + Pip\n",
        "  !sudo apt-get update -y\n",
        "  !sudo apt-get install python3.9 python3-pip python3.9-distutils python3.9-dev libpython3.9-dev python3.9-venv -y\n",
        "\n",
        "  #When updating to Python V3.10 File permissions on the Installed files are wrong. They can be seen in this File Viewer but can NOT be seen or used by the app itself.\n",
        "  #!sudo apt-get install python3.10 python3-pip python3.10-distutils python3.10-dev libpython3.10-dev python3.10-venv -y\n",
        "\n",
        "  #Change alternatives\n",
        "  !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 3\n",
        "\n",
        "  #Update pip\n",
        "  %cd {file_path}\n",
        "  !curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "  !python3 get-pip.py --force-reinstall\n",
        "  !python -m pip install --upgrade pip\n",
        "  !pip install --upgrade setuptools\n",
        "  !pip install pillow==9.3.0\n",
        "\n",
        "\n",
        "  #Handle colab dependencies - Archive this code for the moment.\n",
        "  #!ln -s /usr/local/lib/python3.8/dist-packages/google /usr/local/lib/python3.9/dist-packages/google\n",
        "  #!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "\n",
        "  #Create InvokeAI root\n",
        "  import os\n",
        "  os.environ['INVOKEAI_ROOT'] = file_path\n",
        "  if not os.path.exists(file_path):\n",
        "    os.makedirs(invokeai_root)\n",
        "\n",
        "\n",
        "  #Create the virtual environment + Download default Models\n",
        "  %cd {file_path}\n",
        "\n",
        "  #On 2nd run, Do an \"upgrade\" to get system variables to load quickly.\n",
        "  if os.path.exists(noUpdate):\n",
        "    !python -m venv .venv --prompt InvokeAI\n",
        "\n",
        "    #Update via a GIT pull\n",
        "    #!source .venv/bin/activate; pip install \"invokeai @ https://github.com/invoke-ai/InvokeAI/archive/refs/tags/v3.0.1rc2.zip\" --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117 --upgrade\n",
        "\n",
        "    #Update fully with PIP\n",
        "    !source .venv/bin/activate; pip install InvokeAI[xformers]==3.0.1rc2 --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117 --upgrade\n",
        "\n",
        "  if not os.path.exists(noUpdate):\n",
        "    !python -m venv .venv --prompt InvokeAI\n",
        "    !source .venv/bin/activate; python -m pip install --upgrade pip\n",
        "\n",
        "    #Install via a GIT pull\n",
        "    #!source .venv/bin/activate; pip install \"invokeai @ https://github.com/invoke-ai/InvokeAI/archive/refs/tags/v3.0.1rc2.zip\" --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "    #Install flully with PIP.\n",
        "    !source .venv/bin/activate; pip install InvokeAI[xformers]==3.0.1rc2 --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "    !mkdir {outpath}\n",
        "    !cd {file_path}\n",
        "\n",
        "    if skip_default_models == \"Yes\":\n",
        "      !source .venv/bin/activate; invokeai-configure --yes --skip-sd-weights\n",
        "    if skip_default_models == \"No\":\n",
        "      !source .venv/bin/activate; invokeai-configure --yes\n",
        "\n",
        "    !mkdir {noUpdate}\n",
        "\n",
        "\n",
        "  ## Edit invokeai.yaml\n",
        "  !sed -i 's/max_loaded_models: 3/max_loaded_models: 2/' invokeai.yaml\n",
        "  !sed -i 's/max_cache_size: 6.0/max_cache_size: 6.0/' invokeai.yaml\n",
        "  !sed -i 's/max_vram_cache_size: 2.75/max_vram_cache_size: 4.0/' invokeai.yaml\n",
        "  if xformers == \"Disabled\":\n",
        "    !sed -i 's/xformers_enabled: true/xformers_enabled: false/' invokeai.yaml\n",
        "  if xformers == \"Enabled\":\n",
        "    !sed -i 's/xformers_enabled: false/xformers_enabled: true/' invokeai.yaml\n",
        "  if nsfw_checker == \"Disabled\":\n",
        "    !sed -i 's/nsfw_checker: true/nsfw_checker: false/' invokeai.yaml\n",
        "  if nsfw_checker == \"Enabled\":\n",
        "    !sed -i 's/nsfw_checker: false/nsfw_checker: true/' invokeai.yaml\n",
        "\n",
        "  #Download custom checkpoint models\n",
        "  if custom_model_url != \"None\":\n",
        "    %cd {file_path}/autoimport/main\n",
        "    !wget -nc {file_path}/autoimport/main {custom_model_url}\n",
        "\n",
        "  #Download custom VAE\n",
        "  if custom_vae_url != \"None\":\n",
        "    %cd {file_path}/autoimport/main\n",
        "    !wget -nc {file_path}/autoimport/main {custom_vae_url}\n",
        "\n",
        "  #Import Diffuser Model\n",
        "  if custom_diffuser_hugging_face_id != \"None\":\n",
        "    %cd {file_path}/autoimport/main\n",
        "    !git clone --depth 1 https://huggingface.co/{custom_diffuser_hugging_face_id}\n",
        "\n",
        "  %cd {file_path}\n",
        "\n",
        "  #Clear Output\n",
        "  clear_output()"
      ],
      "metadata": {
        "id": "NO3XyDPsTJ2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnO01U-W6Yjp"
      },
      "outputs": [],
      "source": [
        "#@title 3. Start InvokeAI. { display-mode: \"form\" }\n",
        "#@markdown ### Starting the App\n",
        "#@markdown This step takes either 2-3 mins to start InvokeAI or 5-6 mins if you have selected a diffuser model. <br>\n",
        "#@markdown Diffuser models that are auto imported are NOT selected by default and must be chosen from the menu in app.\n",
        "\n",
        "#@markdown ### Notes about connection types.\n",
        "#@markdown #### Serveo = Almost, always connects however, it can drop your connection if a HTML error occurs, Simply wait for the images to finish generating, stop an re-start this step.\n",
        "#@markdown #### Localtunnel = Once it gets going it is quite stable but often has \"502\" Errors, You must wait for THEM to fix it, please try another connection type.\n",
        "#@markdown #### NGROK = Very stable but requires a token, see the \"configuration\" step for more details.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "%cd {file_path}\n",
        "import os\n",
        "\n",
        "if Version == \"2.3.5.post2\":\n",
        "  if connection_type == \"Serveo\":\n",
        "    if custom_diffuser_hugging_face_id != \"None\":\n",
        "      !ssh -o StrictHostKeyChecking=no -o ServerAliveInterval=60 -R 80:localhost:9090 serveo.net & !source {file_path}/.venv/bin/activate; invokeai --web --host 0.0.0.0 --outdir={outpath} --autoimport {custom_diffuser_hugging_face_id}\n",
        "    if custom_diffuser_hugging_face_id == \"None\":\n",
        "      !ssh -o StrictHostKeyChecking=no -o ServerAliveInterval=60 -R 80:localhost:9090 serveo.net & !source {file_path}/.venv/bin/activate; invokeai --web --host 0.0.0.0 --outdir={outpath}\n",
        "\n",
        "  if connection_type == \"Localtunnel\":\n",
        "    print(\"How to connect to localtunnel:\");\n",
        "    print(\"A localtunnel Interface connection is generated here, To use this, please do the following \")\n",
        "    print(\"1. Copy this IP address\")\n",
        "    !curl ipv4.icanhazip.com\n",
        "    print(\"2. Click the random 'https://XXX-YYY-ZZZ.loca.lt' link that is generated below.\")\n",
        "    print(\"3. Paste the IP into the provided box and submit. \")\n",
        "    print(\" \")\n",
        "    print(\"Note: An error of '502 Bad Gateway' typically is an error at Localtunnels end. A '504 Gateway Time-out' Error means invokeai has not started yet.\")\n",
        "    print(\" \")\n",
        "    !npm install -g localtunnel\n",
        "    if custom_diffuser_hugging_face_id != \"None\":\n",
        "      !npx localtunnel --port 9090 & !source {file_path}/.venv/bin/activate; invokeai --web --host 0.0.0.0 --outdir={outpath} --autoimport {custom_diffuser_hugging_face_id}\n",
        "    if custom_diffuser_hugging_face_id == \"None\":\n",
        "      !npx localtunnel --port 9090 & !source {file_path}/.venv/bin/activate; invokeai --web --host 0.0.0.0 --outdir={outpath}\n",
        "\n",
        "\n",
        "  if connection_type == \"NGROK\":\n",
        "    if ngrok_token == \"None\":\n",
        "      print(\"You have Selected NGROK but did not supply an NGROK token.\")\n",
        "      print(\"Falling back to a 'Serveo' connection type.\")\n",
        "      print(\"Please either add an NGROK token to step 1, re-run step 1, then re-run this step, or just re-run this step to use 'Servio'.\")\n",
        "      connection_type = \"Serveo\"\n",
        "    if ngrok_token != \"None\":\n",
        "      !pip install pyngrok --quiet\n",
        "      from pyngrok import ngrok\n",
        "      ngrok.kill()\n",
        "      ngrok.set_auth_token(ngrok_token)\n",
        "      public_url = ngrok.connect(9090).public_url\n",
        "      print(f'InvokeAI Public URL: {public_url}')\n",
        "      if custom_diffuser_hugging_face_id != \"None\":\n",
        "        !source {file_path}/.venv/bin/activate; invokeai --web --host 0.0.0.0 --outdir={outpath} --autoimport {custom_diffuser_hugging_face_id}\n",
        "      if custom_diffuser_hugging_face_id == \"None\":\n",
        "        !source {file_path}/.venv/bin/activate; invokeai --web --host 0.0.0.0 --outdir={outpath}\n",
        "\n",
        "\n",
        "if Version == \"Version 3\":\n",
        "\n",
        "  if connection_type == \"Serveo\":\n",
        "    !ssh -o StrictHostKeyChecking=no -o ServerAliveInterval=60 -R 80:localhost:9090 serveo.net & !source {file_path}/.venv/bin/activate; invokeai-web --outdir={outpath}\n",
        "\n",
        "  if connection_type == \"Localtunnel\":\n",
        "    print(\"How to connect to localtunnel:\");\n",
        "    print(\"A localtunnel Interface connection is generated here, To use this, please do the following \")\n",
        "    print(\"1. Copy this IP address\")\n",
        "    !curl ipv4.icanhazip.com\n",
        "    print(\"2. Click the random 'https://XXX-YYY-ZZZ.loca.lt' link that is generated below.\")\n",
        "    print(\"3. Paste the IP into the provided box and submit. \")\n",
        "    print(\" \")\n",
        "    print(\"Note: An error of '502 Bad Gateway' typically is an error at Localtunnels end. A '504 Gateway Time-out' Error means invokeai has not started yet.\")\n",
        "    print(\" \")\n",
        "    !npm install -g localtunnel\n",
        "    !npx localtunnel --port 9090 & !source {file_path}/.venv/bin/activate; invokeai-web --outdir={outpath}\n",
        "\n",
        "  if connection_type == \"NGROK\":\n",
        "    if ngrok_token == \"None\":\n",
        "      print(\"You have Selected NGROK but did not supply an NGROK token.\")\n",
        "      print(\"Falling back to a 'Serveo' connection type.\")\n",
        "      print(\"Please either add an NGROK token to step 1, re-run step 1, then re-run this step, or just re-run this step to use 'Servio'.\")\n",
        "      connection_type = \"Serveo\"\n",
        "    if ngrok_token != \"None\":\n",
        "      !pip install pyngrok --quiet\n",
        "      from pyngrok import ngrok\n",
        "      ngrok.kill()\n",
        "      ngrok.set_auth_token(ngrok_token)\n",
        "      public_url = ngrok.connect(9090).public_url\n",
        "      print(f'InvokeAI Public URL: {public_url}')\n",
        "      !source {file_path}/.venv/bin/activate; invokeai-web --outdir={outpath}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}