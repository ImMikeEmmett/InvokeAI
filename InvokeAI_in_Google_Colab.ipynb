{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy86JeXPHQmW"
      },
      "source": [
        "# InvokeAI in Google Colab\n",
        "\n",
        "This is a tool to use Google colab to run the AI image generation tool: Invokeai (https://invoke-ai.github.io/InvokeAI/).\n",
        "This automatically builds itself and can import custom models, It can connect to Google drive to save your images.\n",
        "It also has the option of running entirely from Google drive to vastly speed up the time it takes to start, However, over 20Gb of Google Drive space is required! However it changes subsequent startup times from 15-20 mins to 5-6 mins.\n",
        "\n",
        "Make sure to enable GPU, Edit > Notebook Settings > Hardware accelerator > GPU\n",
        "\n",
        "To start, Click \"Runtime\" > \"Run All\". Alternaivly you can click the \"play\" button on each step below one after the other, No need to wait for the previous steps to finish as they will join a queue.<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cEAEBY2sFdGR"
      },
      "outputs": [],
      "source": [
        "#@title 1. Configuration { display-mode: \"form\" }\n",
        "#@markdown #Instance Type\n",
        "#@markdown **Google_Drive** = Stores ALL files in your Google drive, This can take over 20Gb of space (dependent on your settings), but will start up much faster as it does not download invokeai at each run. To re-run the full install please use the \"Rebuild\" feature in advanced settings, or alternativly delete the whole install directory. <br>\n",
        "#@markdown **Persistent** = Stores only your images in Google drive, in a folder called \"/invokeai/invokeaiOutputV3\".<br>\n",
        "#@markdown **Temporary** (NOT recomended) = Everything is stored in the runtime and is removed when the runtime ends or crashes, make sure to download your images! <br><br>\n",
        "#@markdown **Rough Startup times:** <br>\n",
        "#@markdown Google_Drive, First run, or any \"Persistent/Temporary\" run = 15-20 mins <br>\n",
        "#@markdown Google_Drive, Subsiquent runs, 6-7 mins.\n",
        "Type = \"Google_Drive\" #@param ['Google_Drive','Persistent','Temporary'] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #Connection Type.\n",
        "#@markdown Localtunnel: Stable once connected, but sometimes has issues.<br>\n",
        "#@markdown Serveo: less stable, requires no setup. As an alternative to Localtunnel<br>\n",
        "#@markdown NGROK: (Recomended) Highly stable but needs a little setting up, An NGROK token is required, sign up for free and get one here: https://dashboard.ngrok.com/get-started/your-authtoken Once you have the token, please put it in below.<br>\n",
        "connection_type = \"Localtunnel\"  #@param [\"Serveo\",\"Localtunnel\",\"NGROK\"]\n",
        "ngrok_token = \"None\" #@param ['None'] {allow-input: true}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #NSFW Checker - This has been moved into the interface.<br>\n",
        "#@markdown This checks outputs for \"Not Safe For Work\" content and obscures the image. This is not 100% reliable.<br>\n",
        "#@markdown To activate this, in the top right corner choose the three lines > Settings > Generations > and Toggle \"Enable NSFW checker\" as desired.\n",
        "\n",
        "#nsfw_checker = \"Enabled\" #@param ['Enabled' ,'Disabled'] {type:\"string\"}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Models { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Skip Default Models.<br><br>\n",
        "#@markdown If you are not intending to use them, it is HIGHLY recomended to skip the default models. as this will save 20+GB of downloads and about 10 mins of loading.<br>\n",
        "skip_default_models = \"No\" #@param [\"Yes\",\"No\"]\n",
        "\n",
        "#@markdown With all custom model types if you are using a \"Google_Drive\" type install, you can run this once to generate the folder structure and manually upload models into google drive into the folder /invokeai/invokeaiV3/autoimport/RELAVENT_FOLDER (e.g. /autoimport/vae) or you can use one of the below methods to add models into any install type.<br>\n",
        "\n",
        "#@markdown Custom Diffuser Model\n",
        "custom_diffuser_hugging_face_id = \"None\" #@param [\"None\",\"kebab111/crosskemono\", \"dreamlike-art/dreamlike-photoreal-2.0\", \"stablediffusionapi/disney-pixal-cartoon\"] {allow-input: true}\n",
        "#@markdown Custom Safetensor or Checkpoint models <br>\n",
        "custom_model_url = \"None\" #@param [\"None\",\"https://huggingface.co/ffggggfg/Crosskemono/resolve/main/crosskemonoFurryModel_crosskemono25.safetensors\"] {allow-input: true}\n",
        "custom_vae_url = \"None\" #@param [\"None\",\"https://huggingface.co/ffggggfg/Crosskemono/resolve/main/Crosskemono2.vae.pt\"] {allow-input: true}\n",
        "\n",
        "# #@markdown If you have selected a custom diffuser model it will be auto imported and it is selectable from the dropdown menu in app. <br>\n",
        "# #@markdown Custom .safetensor or .checkpoint models are stored in /content/invokeai/CustomModels and must be manually added via the GUI after it starts. Your Custom VAE will be stored in /content/invokeai/CustomVae <br>\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown LoRA <br>\n",
        "#@markdown To import a LoRA please please input a hugging face repo ID or the URL to your LoRA file.<br>\n",
        "HuggingFace_LoRA_Repo_ID = \"None\" #@param [\"None\", \"artificialguybr/LogoRedmond-LogoLoraForSDXL\"] {allow-input: true}\n",
        "custom_LoRA_url = \"None\" #@param [\"None\"] {allow-input: true}\n",
        "\n",
        "\n",
        "#@markdown ControlNet <br>\n",
        "#@markdown To import a ControlNet please input a hugging face repo ID or the URL to your ControlNet file.<br>\n",
        "HuggingFace_ControlNet_Repo_ID = \"None\" #@param [\"None\", \"CrucibleAI/ControlNetMediaPipeFace\"] {allow-input: true}\n",
        "custom_ControlNet_url = \"None\" #@param [\"None\"] {allow-input: true}\n"
      ],
      "metadata": {
        "id": "g9611wcnE3e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Advanced Options { display-mode: \"form\" }\n",
        "\n",
        "#@markdown #Version\n",
        "#@markdown By default this application uses \"The latest official release of InvokeAI\" however if you wish to use a specific version please enter its version code below.<br>\n",
        "#@markdown Please be aware, If you are using a \"Google_Drive\" version of this program. DOWNGRADING is not officially supported. It may work, it may not, If this does break InvokeAI please DELETE the whole folder /Google_Drive/InvokeAI/invokeaiV3 from https://drive.google.com/, If required please backup your \"Autoimport\" folder. <br>\n",
        "#@markdown Some recomeneded older versions can be located in the dropdown. but any version 3.0.2a1 or newer should work.\n",
        "Version = \"Default\" #@param [\"Default\",\"3.1.0\",\"3.0.2.post1\",\"3.0.2a1\"] {allow-input: true}\n",
        "\n",
        "#@markdown #Rebuild\n",
        "#@markdown If you are having any issues with a GoogleDrive install of InvokeAI but want to keep your imported models and settings, set this to \"Yes\" to force a rebuild of the app. <br>\n",
        "#@markdown Additionally some settings such as \"Skip defult models\" are ignored on subsiquent runs, use this to run those steps again. <br>\n",
        "\n",
        "Rebuild = \"No\" #@param [\"Yes\",\"No\"]\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #Textual Inversion Training mode - This is VERY much in the eirly devlopemnt stage - All options in step \"6\" MUST be configured.\n",
        "#@markdown This mode does not run InvokeAI, it instead uses its \"Textual inversion Training\" feature to generate a .pt model <br>\n",
        "#@markdown it is HIGHLY recomended that you run this from Google Drive. <br>\n",
        "#@markdown Place the images you wish to train with in \"invokeaiOutputV3/text-inversion-training-data/MODEL_NAME\" The exact path will vary depending on the mode you choose, the MODEL_NAME is set in step 6 below.<br>\n",
        "#@markdown InvokeAI Guide: https://invoke-ai.github.io/InvokeAI/features/TRAINING/\n",
        "ti_mode = \"No\" #@param ['Yes','No'] {allow-input: false}\n",
        "\n"
      ],
      "metadata": {
        "id": "6WDsQHKoEj7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Build and Configure, Invokeai V3 { display-mode: \"form\" }\n",
        "#@markdown This takes about 15 mins to finish + some extra time to download custom models. <br>\n",
        "#@markdown Version 3 Downloads all models during the build phase.<br>\n",
        "#@markdown It will auto add all models to the app.\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#Set up temporary storage if running in \"Temporary\" mode.\n",
        "if Type == \"Temporary\":\n",
        "    file_path = '/content/invokeai'\n",
        "    outpath = '/content/invokeai/output'\n",
        "    noUpdate = '/content/invokeai/noUpdate'\n",
        "    import os\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "\n",
        "# Mount and set up Google drive if running in \"Persistent\" mode.\n",
        "if Type == \"Persistent\":\n",
        "  file_path = '/content/invokeai'\n",
        "  outpath = '/content/drive/MyDrive/invokeai/invokeaiOutputV3'\n",
        "  noUpdate = '/content/invokeai/noUpdate'\n",
        "  import os\n",
        "  from google.colab import drive\n",
        "  if not os.path.exists(file_path):\n",
        "    drive.mount('/content/drive')\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "\n",
        "# Mount and set up Google drive if running in \"Google_Drive\" mode.\n",
        "if Type == \"Google_Drive\":\n",
        "  file_path = '/content/drive/MyDrive/invokeai/invokeaiV3'\n",
        "  outpath = '/content/drive/MyDrive/invokeai/invokeaiOutputV3'\n",
        "  noUpdate = '/content/drive/MyDrive/invokeai/invokeaiV3/noUpdate'\n",
        "\n",
        "  import os\n",
        "  from google.colab import drive\n",
        "  if not os.path.exists(file_path):\n",
        "    drive.mount('/content/drive')\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "\n",
        "#Action the rebuild flag.\n",
        "if Rebuild == \"Yes\":\n",
        "  !sudo rm -R {noUpdate}\n",
        "\n",
        "#Install Python + Pip\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.11 python3-pip python3.11-distutils python3.11-dev libpython3.11-dev python3.11-venv -y\n",
        "\n",
        "#Update pip\n",
        "%cd {file_path}\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3 get-pip.py --force-reinstall\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install --upgrade setuptools\n",
        "\n",
        "#Install some Google colab dependencies.\n",
        "!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "#Create InvokeAI root\n",
        "import os\n",
        "os.environ['INVOKEAI_ROOT'] = file_path\n",
        "if not os.path.exists(file_path):\n",
        "  os.makedirs(invokeai_root)\n",
        "\n",
        "#Create the virtual environment + Download default Models\n",
        "%cd {file_path}\n",
        "\n",
        "#On 2nd run, Do an \"upgrade\" to get system variables to load quickly.\n",
        "if os.path.exists(noUpdate):\n",
        "  !python -m venv .venv --prompt InvokeAI\n",
        "  if Version==\"Default\":\n",
        "    !source .venv/bin/activate; python -m pip install InvokeAI[xformers] --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117 --upgrade\n",
        "  if Version != \"Default\":\n",
        "    !source .venv/bin/activate; python -m pip install InvokeAI[xformers]=={Version} --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117 --upgrade\n",
        "\n",
        "\n",
        "#PIP First time install of InvokeAI.\n",
        "if not os.path.exists(noUpdate):\n",
        "  !python -m venv .venv --prompt InvokeAI\n",
        "  !source .venv/bin/activate; python -m pip install --upgrade pip\n",
        "\n",
        "  if Version==\"Default\":\n",
        "    !source .venv/bin/activate; python -m pip install InvokeAI[xformers] --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "  if Version != \"Default\":\n",
        "    !source .venv/bin/activate; python -m pip install InvokeAI[xformers]=={Version} --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "  !mkdir {outpath}\n",
        "  !cd {file_path}\n",
        "\n",
        "  if skip_default_models == \"Yes\":\n",
        "    !source .venv/bin/activate; invokeai-configure --yes --skip-sd-weights\n",
        "  if skip_default_models == \"No\":\n",
        "    !source .venv/bin/activate; invokeai-configure --yes\n",
        "\n",
        "  !mkdir {noUpdate}\n",
        "\n",
        "## Edit invokeai.yaml\n",
        "\n",
        "#Toggle the NSFW checker - Archived\n",
        "#if nsfw_checker == \"Disabled\":\n",
        "#  !sed -i 's/nsfw_checker: true/nsfw_checker: false/' invokeai.yaml\n",
        "#if nsfw_checker == \"Enabled\":\n",
        "#  !sed -i 's/nsfw_checker: false/nsfw_checker: true/' invokeai.yaml\n",
        "\n",
        "#Download custom checkpoint models\n",
        "if custom_model_url != \"None\":\n",
        "  %cd {file_path}/autoimport/main\n",
        "  !wget -nc {file_path}/autoimport/main {custom_model_url}\n",
        "\n",
        "#Download custom VAE\n",
        "if custom_vae_url != \"None\":\n",
        "  %cd {file_path}/autoimport/vae\n",
        "  !wget -nc {file_path}/autoimport/vae {custom_vae_url}\n",
        "\n",
        "#Import Diffuser Model\n",
        "if custom_diffuser_hugging_face_id != \"None\":\n",
        "  %cd {file_path}/autoimport/main\n",
        "  !git clone --depth 1 --verbose --progress https://huggingface.co/{custom_diffuser_hugging_face_id}\n",
        "\n",
        "#Import LoRA\n",
        "if custom_LoRA_url != \"None\":\n",
        "  %cd {file_path}/autoimport/lora\n",
        "  !wget -nc {file_path}/autoimport/lora {custom_LoRA_url}\n",
        "if HuggingFace_LoRA_Repo_ID != \"None\":\n",
        "  %cd {file_path}/autoimport/lora\n",
        "  !git clone --depth 1 --verbose --progress https://huggingface.co/{HuggingFace_LoRA_Repo_ID}\n",
        "\n",
        "#Import ControlNet\n",
        "if custom_ControlNet_url != \"None\":\n",
        "  %cd {file_path}/autoimport/controlnet\n",
        "  !wget -nc {file_path}/autoimport/controlnet {custom_ControlNet_url}\n",
        "if HuggingFace_ControlNet_Repo_ID != \"None\":\n",
        "  %cd {file_path}/autoimport/controlnet\n",
        "  !git clone --depth 1 --verbose --progress https://huggingface.co/{HuggingFace_ControlNet_Repo_ID}\n",
        "\n",
        "%cd {file_path}\n",
        "\n",
        "#Clear Output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "NO3XyDPsTJ2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnO01U-W6Yjp"
      },
      "outputs": [],
      "source": [
        "#@title 5. Start InvokeAI. { display-mode: \"form\" }\n",
        "if ti_mode == \"No\":\n",
        "  #@markdown ### Starting the App\n",
        "  #@markdown This step takes about 30 seconds to generate your URL but 2-3 mins before it will work fully!. <br>\n",
        "  #@markdown Diffuser models that are auto imported are NOT selected by default and must be chosen from the menu in app.\n",
        "\n",
        "  #@markdown ### Notes about connection types.\n",
        "  #@markdown #### Localtunnel = Once it gets going it is quite stable but often has \"502\" Errors, You must wait for THEM to fix it, please try another connection type.\n",
        "  #@markdown #### Serveo = Almost, always connects however, it can drop your connection if a HTML error occurs, Simply wait for the images to finish generating, stop an re-start this step.\n",
        "  #@markdown #### NGROK = Very stable but requires a token, see the \"configuration\" step for more details.\n",
        "\n",
        "  #@markdown ---\n",
        "\n",
        "  %cd {file_path}\n",
        "  import os\n",
        "\n",
        "  if connection_type == \"Serveo\":\n",
        "    !ssh -o StrictHostKeyChecking=no -o ServerAliveInterval=60 -R 80:localhost:9090 serveo.net & . {file_path}/.venv/bin/activate; invokeai-web --outdir={outpath}\n",
        "\n",
        "  if connection_type == \"Localtunnel\":\n",
        "    print(\"How to connect to localtunnel:\");\n",
        "    print(\"A localtunnel Interface connection is generated here, To use this, please do the following \")\n",
        "    print(\"1. Copy this IP address\")\n",
        "    !curl ipv4.icanhazip.com\n",
        "    print(\"2. Click the random 'https://XXX-YYY-ZZZ.loca.lt' link that is generated below.\")\n",
        "    print(\"3. Paste the IP into the provided box and submit. \")\n",
        "    print(\" \")\n",
        "    print(\"Note: An error of '502 Bad Gateway' typically is an error at Localtunnels end. A '504 Gateway Time-out' Error means invokeai has not started yet.\")\n",
        "    print(\" \")\n",
        "    !npm install -g localtunnel\n",
        "    !npx localtunnel --port 9090 & . {file_path}/.venv/bin/activate; invokeai-web --outdir={outpath}\n",
        "\n",
        "  if connection_type == \"NGROK\":\n",
        "    if ngrok_token == \"None\":\n",
        "      print(\"You have Selected NGROK but did not supply an NGROK token.\")\n",
        "      print(\"Falling back to a 'Serveo' connection type.\")\n",
        "      print(\"Please either add an NGROK token to step 1, re-run step 1, then re-run this step, or just re-run this step to use 'Servio'.\")\n",
        "      connection_type = \"Serveo\"\n",
        "    if ngrok_token != \"None\":\n",
        "      !pip install pyngrok --quiet\n",
        "      from pyngrok import ngrok\n",
        "      ngrok.kill()\n",
        "      ngrok.set_auth_token(ngrok_token)\n",
        "      public_url = ngrok.connect(9090).public_url\n",
        "      print(f'InvokeAI Public URL: {public_url}')\n",
        "      ! . {file_path}/.venv/bin/activate; invokeai-web --outdir={outpath}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. InvokeAI Textual Inversion Training. ALL OPTIONS ARE MANDATORY AND WILL BE CUSTOM TO YOU! { display-mode: \"form\" }\n",
        "if ti_mode == \"Yes\":\n",
        "\n",
        "  #@markdown # Textual Inversion Training.<br>\n",
        "  #@markdown ## Please place the files in either .jpg/.jpeg or .png into the folder relavent to your \"type\" selected above, in your OUTPUT location \"invokeaiOutputV3/text-inversion-training-data/modelname\" where the modelname is EXACTLY what you have set below. (capitlisation included) <br><br>\n",
        "\n",
        "  # TPU does not work, commenting out comment about it.\n",
        "  # #@markdown ## Allthough not required, it is recomended to swap to a TPU if you are NOT using \"Mixed precision\", as this will be aproximatly 2.5X faster. You can do this in \"Edit\" > \"Notebook Settings\" > \"TPU\". <br><br>\n",
        "\n",
        "  #@markdown ## Model Name.\n",
        "  #@markdown Textual Inversion Name, this is both what you will need to include in the prompt to use this model and part of the file path used by this process.\n",
        "  model_name_ti = \"MODEL_NAME\" #@param ['MODEL_NAME'] {allow-input: true}\n",
        "\n",
        "  #@markdown ## Base Model.\n",
        "  #@markdown What model should the Textual Inversion be based on? This must match the name in InvokeAI EXACTLY, captiliation included.\n",
        "  modelname_ti = \"stable-diffusion-v1-5\" #@param ['stable-diffusion-v1-5'] {allow-input: true}\n",
        "\n",
        "  #@markdown ## Number of Steps\n",
        "  #@markdown Set the maximum training steps, The more steps the longer it takes to run however the more accurate it will be.<br>\n",
        "  #@markdown Any checkpoint can be used\n",
        "  steps_ti = \"5000\" #@param ['1000','3000','5000','10000'] {allow-input: true}\n",
        "\n",
        "  #@markdown ## Checkpoint Frequency.\n",
        "  #@markdown How often should a checkpoint be made? The more often a checkpoint is made the more space this takes up, however the less progress is lost if this crashes or is stopped.\n",
        "  checkpoint_frequency = \"250\" #@param ['10','100','250','500','1000'] {allow-input: true}\n",
        "\n",
        "  #@markdown ## Resolution.\n",
        "  #@markdown Model resolution - This should be the same as the base model, and is a square e.g. 512 = 512X512\n",
        "  resolution_ti = \"512\" #@param ['512','768','1024'] {allow-input: true}\n",
        "\n",
        "  #@markdown ## Learnable property.\n",
        "  #@markdown What do you want to take from the images, Style or Object?\n",
        "  learnable_property = \"style\" #@param ['style','object'] {allow-input: false}\n",
        "\n",
        "  #@markdown ## Mixed Presision\n",
        "  #@markdown Allow \"Vae Precision\" of \"fp16\"\n",
        "  mixed_precision_ti = \"fp16\" #@param ['no','fp16'] {allow-input: false}\n",
        "\n",
        "  #@markdown ---\n",
        "  #@markdown ## Currently there seems to be an issue where resuming a run does not work (it simply starts again, but looks like it is resuming) <br>\n",
        "  #@markdown This \"Works\" and the settings are retained for when it is fixed at invokeai's end. <br><br>\n",
        "\n",
        "  #@markdown ## Resume an Old Traning Run.\n",
        "  #@markdown Resume training from an existing training run? If this is set to \"Yes\" and no pre-exisiting run with this name has reached a checkpoint, this will not run.\n",
        "  continue_ti = \"No\" #@param ['Yes','No'] {allow-input: false}\n",
        "\n",
        "  #@markdown ## Resume From What Checkpoint Number? - This setting is Ignored if \"continue_ti\" is \"No\"\n",
        "  #@markdown This is the number of the checkpoint you would like to resume from, in the ouput directory will be files called \"checkpoint-XXX\" choose the highest number.<br>\n",
        "  checkpoint_resume = \"500\" #@param ['250'] {allow-input: true}\n",
        "\n",
        "\n",
        "\n",
        "  #Make directorys if they dont exist\n",
        "  directory_path = os.path.join(outpath, \"text-inversion-output\", model_name_ti)\n",
        "  if not os.path.exists(directory_path):\n",
        "      os.makedirs(directory_path)\n",
        "  directory_path = os.path.join(outpath, \"text-inversion-training-data\", model_name_ti)\n",
        "  if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "\n",
        "  #Run the Textual Inversion Training First run\n",
        "  if continue_ti == \"No\":\n",
        "    ! . {file_path}/.venv/bin/activate; invokeai-ti --model={modelname_ti} --resolution={resolution_ti} --learnable_property={learnable_property} --initializer_token='*' --placeholder_token='<{model_name_ti}>' --train_data_dir={outpath}/text-inversion-training-data/{model_name_ti}/ --output_dir={outpath}/text-inversion-output/{model_name_ti}/ --train_batch_size=4 --gradient_accumulation_steps=1 --max_train_steps={steps_ti} --learning_rate=0.0005 --scale_lr  --lr_scheduler=constant --mixed_precision={mixed_precision_ti} --only_save_embeds --checkpointing_steps {checkpoint_frequency} --save_steps {checkpoint_frequency}\n",
        "\n",
        "  #Run the Textual Inversion Training in Continue mode\n",
        "  if continue_ti == \"Yes\":\n",
        "    ! . {file_path}/.venv/bin/activate; invokeai-ti --model={modelname_ti} --resolution={resolution_ti} --learnable_property={learnable_property} --initializer_token='*' --placeholder_token='<{model_name_ti}>' --train_data_dir={outpath}/text-inversion-training-data/{model_name_ti}/ --output_dir={outpath}/text-inversion-output/{model_name_ti}/ --train_batch_size=1 --gradient_accumulation_steps=4 --max_train_steps={steps_ti} --learning_rate=0.0005 --scale_lr  --lr_scheduler=constant --mixed_precision={mixed_precision_ti} --only_save_embeds --checkpointing_steps {checkpoint_frequency} --save_steps {checkpoint_frequency} --resume_from_checkpoint=\"checkpoint-{checkpoint_resume}\"\n"
      ],
      "metadata": {
        "id": "v7CWShtNKMZ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
